ğŸ¤– SentinelRAG ~ A Multi-Agent, Grounded Retrieval-Augmented AI Chatbot

ğŸ“Œ Overview

    SentinelRAG is a production-grade Retrieval-Augmented Generation (RAG) system designed to provide accurate, grounded, and transparent AI responses over user-provided documents.
    It combines semantic vector search with a multi-agent architecture to prevent hallucinations while maintaining a natural conversational experience.

    The system enforces strict grounding rules when documents are relevant and safely falls back to pretrained language model knowledge when no relevant information exists.

ğŸ¯ Motivation

    Large Language Models are powerful but prone to:

    Hallucinations

    Overconfidence

    Mixing prior answers with new queries

    SentinelRAG was designed to solve these issues by:

    Separating responsibilities into specialized agents

    Enforcing strict document grounding

    Preventing self-reinforcement from previous answers

    Explicitly distinguishing between document-based and general-knowledge answers

ğŸ§  System Architecture

    SentinelRAG uses a multi-agent pipeline:

    Retriever Agent
    Performs vector search and entity-aware re-ranking over indexed documents.

    Analyzer Agent
    Decides how to answer:

    Strict RAG (documents only)

    Safe fallback to general knowledge

    Pure conversational LLM

    Critique Agent
    Evaluates answer faithfulness against the used context.

    Memory Module
    Stores relevant conversational facts and makes them retrievable.
ğŸ” System Workflow
![SentinelRAG Workflow Diagram](assets/sentinelrag_workflow.png)

ğŸ” Workflow Diagram


            User Query
            
            â”‚
            â–¼
            
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Retriever    â”‚
            â”‚ Agent        â”‚
            â”‚ (Vector +    â”‚
            â”‚ Entity Match)â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Analyzer Agent             â”‚
            â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
            â”‚ â€¢ Is context available?   â”‚
            â”‚ â€¢ Is context relevant?    â”‚
            â”‚ â€¢ Should we use memory?   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚           â”‚
                â”‚           â”‚
                â–¼           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Strict RAG   â”‚  â”‚ Safe Fallback LLM   â”‚
            â”‚ (Docs Only) â”‚  â”‚ (General Knowledge) â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â”‚
                â–¼                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Answer Generation (LLM)           â”‚
            â”‚ â€¢ No hallucination                â”‚
            â”‚ â€¢ No prior answer leakage         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
                    Final Answer + Sources
                        â”‚
                        â–¼
                    Critique Agent (Validation)


âœ¨ Key Features

    ğŸ” Semantic Vector Search using ChromaDB

    ğŸ§  Entity-Aware Retrieval & Re-Ranking

    ğŸ”’ Strict Hallucination Prevention

    ğŸ” Conversational Memory Integration

    ğŸ§­ Safe Fallback to Pretrained LLMs

    ğŸ§© Multi-Agent Modular Architecture

    ğŸ“„ Document Upload & Automatic Indexing

    ğŸ–¥ Streamlit Interactive UI

ğŸ§ª Supported Question Types

    â€œWho is X?â€ (entity questions)

    â€œExplain topic Y from the documentsâ€

    â€œSummarize file Zâ€

    Follow-up questions using chat memory

    General questions not covered by documents (explicit fallback)

ğŸ›  Tech Stack

    Python

    ChromaDB (Vector Database)

    Sentence-Transformers (Embeddings)

    Streamlit (Frontend UI)

    Multi-Agent Orchestration

    Retrieval-Augmented Generation (RAG)

ğŸš€ Installation & Setup
    git clone https://github.com/FadiKais1/SentinelRAG-A-Multi-Agent-Retrieval-Augmented-AI-Chatbot.git
    cd SentinelRAG-A-Multi-Agent-Retrieval-Augmented-AI-Chatbot
    python -m venv venv
    venv\Scripts\activate
    pip install -r requirements.txt
    Create a .env file:
    LLM_PROVIDER=nvidia
    NVIDIA_API_KEY=your_key_here
    OPENAI_API_KEY=optional
    Run the application:streamlit run frontend/chatbot_app.py

ğŸ“„ Usage

    Upload .txt or .pdf documents

    Click Reindex Documents

    Ask questions about the uploaded content

    Observe:

    Grounded answers when documents apply

    Explicit fallback when they do not

    Source attribution for transparency

ğŸ§© Design Principles

    Correctness over creativity

    Transparency over hidden behavior

    Explicit fallback instead of silent hallucination

    Separation of concerns via agents

    Explainable decision logic

âš ï¸ Limitations

    Entity extraction uses heuristic rules (not full NER)

    Vector search quality depends on embedding model

    Memory is short-term (configurable)

ğŸ”® Future Improvements

    Named-Entity Recognition (spaCy)

    Hybrid BM25 + Vector retrieval

    Confidence scoring per answer

    Per-document query scoping

    Deployment on Streamlit Cloud / Docker

ğŸ“œ License

    MIT License â€” free to use, modify, and distribute.

ğŸ™Œ Acknowledgements

    Built as a learning-focused yet production-oriented exploration of modern RAG system design and AI safety principles.
